% ================================================================
\section{Methodological Reflections: Framework as Research Infrastructure}\label{sec:framework-role}

\subsection{The Reproducibility Challenge in LLM-Based Empirical Research}

Our multi-agent framework addresses a critical but often overlooked challenge in LLM-driven computational social science: \textbf{the reproducibility crisis at the intersection of stochastic models and complex data pipelines}. While the machine learning community has extensively documented issues with model reproducibility~\cite{gundersen2018state}, LLM-based empirical studies face additional layers of non-determinism: API versioning, rate limiting, prompt engineering variations, and manual result curation. 

Consider the counterfactual scenario without our framework. To replicate our study, a researcher would need to:
\begin{enumerate}
    \item Manually construct 6 prompts (2 sampling methods $\times$ 3 analysis dimensions), risking inconsistent phrasing
    \item Make sequential API calls with ad-hoc error handling, potentially introducing ordering effects
    \item Parse heterogeneous LLM outputs (JSON arrays, markdown code blocks, free text) using brittle regex patterns
    \item Manually reconcile failures, retries, and partial results, creating untracked decision points
\end{enumerate}

Each step introduces a \textbf{garden of forking paths}~\cite{gelman2013garden}---unrecorded analytical choices that appear innocuous but compound into irreproducibility. Our framework collapses this complexity into a single command (\texttt{python run\_multi\_agent\_analysis.py}) with centrally logged parameters (temperature=0.2, max\_tokens=800, model=gpt-4o-mini, random\_seed=42). This is not mere convenience; it is \textbf{methodological infrastructure} that makes LLM experiments auditable and falsifiable.

\subsection{From Fault Tolerance to Epistemic Robustness}

The framework's resilience mechanisms---exponential backoff for rate limits, multi-strategy JSON parsing, timeout detection---are often dismissed as engineering details. However, they encode deeper epistemic commitments about what constitutes a valid experiment when the data generation process is partially stochastic and externally mediated.

During our experiments, we encountered 12 OpenAI rate limit errors (HTTP 429), 5 JSON parsing failures, and 2 network timeouts. \textbf{Without automatic retry and fallback mechanisms, these failures would force a choice}: discard failed tasks (biasing the sample toward ``well-behaved'' API responses) or manually re-run them (introducing temporal confounds, as LLM model weights may update between runs). Both options violate experimental validity. The framework's automatic recovery ensures that \textit{all planned comparisons are executed under identical conditions}, preserving the counterfactual structure necessary for causal inference about sampling strategy effects.

Moreover, the coordinator's performance tracking (Eq.~\ref{eq:agent-score}) reveals a subtle point: \textit{different analysis tasks have different computational profiles}. Our logs show that \texttt{RoleClassifierAgent} required 8.2s median completion time versus 5.1s for \texttt{AnomalyAnalystAgent}, likely due to JSON parsing overhead. In a na√Øve sequential execution, this would introduce task-order dependencies. The framework's capability-based routing decouples task assignment from completion order, ensuring that slow tasks do not bottleneck the pipeline. This architectural decision has methodological implications: it enables \textbf{within-experiment parallelization} without sacrificing reproducibility.

\subsection{Limitations as Windows into Fundamental Trade-offs}

Our study's limitations are not merely technical constraints awaiting future computational resources; they reveal \textbf{fundamental tensions in LLM-based network analysis}.

\textbf{The Sample Size--Statistical Power Paradox}: Our Top-100 analysis yields substantive insights (CETraS discovers mixers and mining pools absent in RWFB) but lacks statistical significance ($p{=}1.0$). Scaling to Top-1000 would improve power but encounters the \textbf{LLM context window bottleneck}: GPT-4o-mini's 128K token limit cannot accommodate 1000 node profiles with full edge lists. This necessitates batched processing, which introduces a new confound---\textit{batch boundaries may fragment communities or separate related entities, distorting LLM reasoning}. The framework's modular architecture positions us to address this via a \texttt{BatchCoordinatorAgent} that intelligently partitions graphs by community structure, but the core trade-off remains: statistical robustness versus semantic coherence within LLM context windows.

\textbf{The Ground Truth Dilemma and the CI Metric's Indirect Validation}: We lack labeled Bitcoin addresses for direct precision/recall evaluation. This is not an oversight but a structural feature of blockchain analysis: \textit{entity labels are themselves contested and often proprietary} (e.g., exchanges may not publicly disclose all cold wallets; mixer operators obfuscate identities by design). Our Consistency Index (CI) responds to this challenge by reframing validation: instead of comparing LLM outputs to an external gold standard, CI assesses \textbf{internal coherence}---whether LLM-generated semantic summaries align with graph-structural properties (Gini coefficients). This operationalizes a pragmatist epistemology~\cite{dewey1938logic}: truth as coherence across independent measurement modalities rather than correspondence to a singular ground truth.

However, CI's binary semantic label ($l \in \{0,1\}$) derived from keyword matching is admittedly crude. A more principled approach would embed the LLM summary and the graph's structural profile (degree distribution, clustering coefficients, shortest path lengths) into a shared semantic space (e.g., via sentence transformers and graph neural networks), then compute cosine similarity. Such an \textbf{embedding-based consistency score} would capture nuanced alignment (e.g., ``moderately centralized'' vs. ``highly centralized'') and is a natural extension within our framework's modular design---requiring only a new \texttt{EmbeddingConsistencyAgent}.

\textbf{Temporal Stationarity and the Single Snapshot Limitation}: Our October 2020 snapshot may not generalize across time. Bitcoin's transaction network evolves through punctuated equilibria: regulatory crackdowns on mixers~\cite{europol2021}, exchange hacks leading to address migrations, and halving events altering mining economics. The framework's asynchronous architecture inherently supports temporal analysis---parallel agents could process monthly snapshots from 2017--2024, enabling longitudinal studies of how sampling bias \textit{itself} varies with network topology. For instance, during periods of extreme centralization (e.g., post-Mt.Gox collapse), RWFB and CETraS might converge; during decentralized phases, they might diverge. Such time-varying bias is a frontier question that the framework enables but our current study does not explore.

\subsection{Future Work as a Research Program}

The limitations above chart a \textbf{research program} rather than a checklist of incremental improvements:

\textbf{1. Multi-LLM Epistemic Ensembles}: Extend the framework to orchestrate heterogeneous LLMs (GPT-4o, Claude Sonnet, LLaMA-3-70B) as epistemic peers. The coordinator would aggregate their outputs not by simple voting but via \textbf{argument-based deliberation}~\cite{prakken2018}---agents justify their classifications, critique each other's rationales, and converge on consensus. This addresses a meta-question: \textit{To what extent are our findings artifacts of GPT-4o-mini's training corpus versus robust cross-model insights?}

\textbf{2. Adaptive Hybrid Sampling with Active Learning}: Develop a \texttt{SamplingPolicyAgent} that dynamically blends RWFB's exploration and CETraS's exploitation based on observed network properties. For instance, if initial sampling reveals high modularity (many disconnected communities), the agent might increase RWFB's weight to ensure cross-community coverage; if initial sampling shows power-law degree distributions, it might increase CETraS's weight to capture tail nodes. This frames sampling as an \textbf{adaptive experimental design problem}~\cite{murphy2005active}, where the sampling strategy itself is learned online.

\textbf{3. Retrieval-Augmented Blockchain Analysis}: Integrate a \texttt{RetrievalAgent} that fetches external context (exchange announcements, regulatory filings, social media discussions) via web search or structured APIs. For example, if the LLM classifies a node as a ``mixer'', the retrieval agent could search for known mixer addresses (e.g., ChipMixer, Wasabi Wallet) and cross-reference. This operationalizes \textbf{Retrieval-Augmented Generation (RAG)}~\cite{lewis2020rag} for blockchain analysis, grounding LLM reasoning in external evidence.

\textbf{4. Causal Sampling Bias Quantification}: Formalize the relationship between sampling strategy and LLM outputs via causal graphs. Treat sampling method as an intervention, graph structure as a mediator, and LLM conclusions as outcomes. Use the framework to conduct \textbf{counterfactual simulations}~\cite{pearl2009causality}: ``If we had used CETraS on RWFB's subgraph structure (via synthetic rewiring), would the LLM's conclusions change?'' This would decompose SDM into \textit{structural drift} (sampling alters graph topology) and \textit{interpretive drift} (LLMs interpret identical graphs differently depending on prompt framing).

\subsection{Positioning This Work: From Tool to Paradigm}

Our contribution extends beyond a software artifact. By co-designing \textbf{metrics (SDM, CI) and infrastructure (multi-agent framework)}, we propose a methodological paradigm for LLM-based graph analysis:
\begin{enumerate}
    \item \textbf{Sampling as an Experimental Variable}: Systematically vary sampling strategies and quantify their effects on downstream conclusions, rather than treating sampling as a fixed preprocessing step.
    \item \textbf{Reproducibility by Design}: Embed logging, retry logic, and parameter management into the experimental infrastructure, making the entire pipeline auditable.
    \item \textbf{Validation via Coherence}: In domains lacking gold-standard labels, assess LLM outputs by their internal consistency with structural properties (CI) and cross-method divergence (SDM).
\end{enumerate}

This paradigm is applicable beyond Bitcoin: social network analysis (does community detection via Louvain vs. Leiden yield different LLM-generated narratives?), citation networks (how does sampling strategy affect LLM assessments of academic impact?), and supply chain networks (do different sampling methods surface different vulnerabilities when analyzed by LLMs?).

The framework's modularity ensures that these extensions require minimal code changes---new agents for new domains, new metrics for new validation criteria---but the core methodological commitments (reproducibility, fault tolerance, systematic comparison) remain constant. In this sense, the framework is not merely a tool for \textit{this} study but \textbf{research infrastructure} for a nascent field: LLM-augmented computational network science.


% ================================================================
% Additional references needed for this section
% Add these to your bibliography:

% \bibitem{gundersen2018state}
% O. E. Gundersen and S. Kjensmo,
% ``State of the art: Reproducibility in artificial intelligence,''
% in \textit{Proc. AAAI Conference on Artificial Intelligence}, 2018.

% \bibitem{gelman2013garden}
% A. Gelman and E. Loken,
% ``The garden of forking paths: Why multiple comparisons can be a problem, even when there is no fishing expedition,''
% Department of Statistics, Columbia University, 2013.

% \bibitem{dewey1938logic}
% J. Dewey, \textit{Logic: The Theory of Inquiry}, Henry Holt and Company, 1938.

% \bibitem{europol2021}
% Europol, ``Largest ever dark web marketplace takedown,'' Press Release, 2021.

% \bibitem{prakken2018}
% H. Prakken, ``Historical overview of formal argumentation,'' 
% in \textit{Handbook of Formal Argumentation}, College Publications, 2018.

% \bibitem{murphy2005active}
% S. A. Murphy, ``An experimental design for the development of adaptive treatment strategies,''
% \textit{Statistics in Medicine}, vol. 24, no. 10, pp. 1455--1481, 2005.

% \bibitem{lewis2020rag}
% P. Lewis et al., ``Retrieval-augmented generation for knowledge-intensive NLP tasks,''
% in \textit{Advances in Neural Information Processing Systems}, 2020.

% \bibitem{pearl2009causality}
% J. Pearl, \textit{Causality: Models, Reasoning, and Inference}, 2nd ed., Cambridge University Press, 2009.
